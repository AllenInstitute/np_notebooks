{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *VBN - May 2024*\n",
    "<img src=\"https://brainmapportal-live-4cc80a57cd6e400d854-f7fdcae.divio-media.net/filer_public_thumbnails/filer_public/6b/da/6bdafa89-61e1-40f8-a517-3186a05f9734/image_sets_and_training_trajectories_diagram.png__1756x1045_q90_subsampling-2.png\" width=\"380\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AIBS_RIG_ID=NP1\n"
     ]
    }
   ],
   "source": [
    "%env AIBS_RIG_ID=NP1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the update/reset shortcut on the desktop before each experiment\n",
    "***\n",
    "***\n",
    "# **Without mouse on stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to enable remote-to-remote symlink creation: try running as admin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1392b005a1649938773c9652ce150b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Elapsed time: 00h 00m 00s'), Label(value='Remember to restart JupyterLab and run u…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import contextlib\n",
    "import time\n",
    "\n",
    "import np_config\n",
    "import np_jobs\n",
    "import np_logging\n",
    "import np_services\n",
    "import np_session\n",
    "import np_workflows\n",
    "from np_workflows import npxc\n",
    "\n",
    "from np_services.resources.zro import ZroError \n",
    "import contextlib\n",
    "\n",
    "logger = np_logging.getLogger()\n",
    "\n",
    "np_workflows.elapsed_time_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Quiet mode\n",
    "**on**  [*default*]\n",
    "- error details are hidden\n",
    "- regular messages displayed (log level = INFO)\n",
    "\n",
    "**off**\n",
    "- full error details (with traceback)\n",
    "- extra messages displayed (log level = DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e972a0e190c467793b4eda9b12beaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=True, button_style='info', description='Quiet mode is on', icon='check', tooltip='Quiet mod…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_workflows.quiet_mode_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Launch apps via RSC\n",
    "[optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with contextlib.suppress(Exception):\n",
    "    np_services.start_rsc_apps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Select mouse and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406d9a914f9841d59cf0a7402c7699fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Select(description='User:', options=('mikayla.carlson', 'ryan.gillis', 'severined'), value='mik…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user, mouse = np_workflows.user_and_mouse_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Check MTrain and select workflow\n",
    "Re-run cell this cell if mouse ID is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa07e229f6044f418c5e9ef1cf8e5c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(GridspecLayout(children=(Label(value='Mouse: 366122', layout=Layout(grid_area='widget001')), La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_workflows.mtrain_widget(mouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[\"VisualBehaviorEPHYS_Task1G_v0.1.2\"][\"EPHYS_1_images_G_3uL_reward\"][\"parameters\"] = {\n",
    "  'task_id': 'DoC',\n",
    "  'catch_frequency': None,\n",
    "  'failure_repeats': 5,\n",
    "  'reward_volume': 0.003,\n",
    "  'volume_limit': 5.0,\n",
    "  'auto_reward_vol': 0.005,\n",
    "  'warm_up_trials': 3,\n",
    "  'auto_reward_delay': 0.15,\n",
    "  'free_reward_trials': 10000,\n",
    "  'min_no_lick_time': 0.0,\n",
    "  'timeout_duration': 0.3,\n",
    "  'pre_change_time': 0.0,\n",
    "  'stimulus_window': 6.0,\n",
    "  'max_task_duration_min': 60.0,\n",
    "  'periodic_flash': [0.25, 0.5],\n",
    "  'response_window': [0.15, 0.75],\n",
    "  'end_after_response': True,\n",
    "  'end_after_response_sec': 3.5,\n",
    "  'change_time_dist': 'geometric',\n",
    "  'change_time_scale': 0.3,\n",
    "  'change_flashes_min': 4,\n",
    "  'change_flashes_max': 12,\n",
    "  'start_stop_padding': 1,\n",
    "  'stimulus': {'class': 'images',\n",
    "    'luminance_matching_intensity': -0.46,\n",
    "    'params': {'image_set': '//allen/programs/braintv/workgroups/nc-ophys/visual_behavior/image_dictionaries/Natural_Images_Lum_Matched_set_ophys_G_2019.05.26.pkl',\n",
    "    'sampling': 'even'}},\n",
    "  'mapping': {'flash_path': '//allen/programs/braintv/workgroups/nc-ophys/1022/replay-stim/flash_250ms.stim',\n",
    "    'gabor_path': '//allen/programs/braintv/workgroups/nc-ophys/1022/replay-stim/gabor_20_deg_250ms.stim'},\n",
    "  'output_dir': 'C:/ProgramData/camstim/output',\n",
    "  'agent_socket': '127.0.0.1:5000',\n",
    "  'stage': 'EPHYS_1_images_G_3uL_reward',\n",
    "  'flash_omit_probability': 0.05,\n",
    "  'max_mapping_duration_min': 35,\n",
    "  'opto_params': {'operation_mode': 'experiment'}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import copy\n",
    "import uuid\n",
    "import functools\n",
    "import requests\n",
    "import pathlib\n",
    "from typing import Literal, Optional, TypeAlias, Any\n",
    "\n",
    "\n",
    "ScriptName: TypeAlias = Literal['mapping', 'behavior', 'replay', 'optotagging']\n",
    "\n",
    "class Workflow(enum.Enum):\n",
    "    \"\"\"Enum for the different session types available .\n",
    "    - can control workflow and paramater sets\n",
    "    \"\"\"\n",
    "    PRETEST = \"pretest\"\n",
    "    HAB = \"hab\"\n",
    "    EPHYS = \"ephys\"\n",
    "      \n",
    "class VBNMixin:\n",
    "    \"\"\"Provides project-specific methods and attributes, mainly related to camstim scripts.\"\"\"\n",
    "    \n",
    "    workflow: Workflow\n",
    "    \"\"\"Enum for particular workflow/session, e.g. PRETEST, HAB_60, HAB_90,\n",
    "    EPHYS.\"\"\"\n",
    "    \n",
    "    session: np_session.PipelineSession\n",
    "    mouse: np_session.Mouse\n",
    "    user: np_session.User\n",
    "    platform_json: np_session.PlatformJson\n",
    "    \n",
    "    commit_hash = '5adfa6e285774719135d0ebcba421f15f6f56168'\n",
    "\n",
    "    task_id = 'replay'\n",
    "        \n",
    "    @property\n",
    "    def script_names(self) -> tuple[ScriptName, ...]:\n",
    "        if self.workflow == Workflow.Hab:\n",
    "            return ('mapping', 'behavior', 'replay')\n",
    "        else:\n",
    "            return ('mapping', 'behavior', 'replay', 'optotagging')\n",
    "    \n",
    "    def get_script_content(self, script_name: str | ScriptName) -> str:\n",
    "        return requests.get(\n",
    "            f'http://stash.corp.alleninstitute.org/projects/VB/repos/visual_behavior_scripts/raw/replay_session/{script_name}_script.py?at={self.commit_hash}',\n",
    "        ).text\n",
    "        \n",
    "    @functools.cached_property\n",
    "    def stage_params(self) -> dict[str, Any]:\n",
    "        \"\"\"All parameters returned from mtrain for the mouse's current stage.\"\"\"\n",
    "        return self.mouse.mtrain.stage['parameters'] | {'replay_id': self.foraging_id}\n",
    "\n",
    "    @property\n",
    "    def foraging_id(self) -> str:\n",
    "        \"\"\"Read-only, created on first read\"\"\"\n",
    "        if not getattr(self, \"_foraging_id\", None):\n",
    "            self._foraging_id = uuid.uuid4().hex\n",
    "        return self._foraging_id\n",
    "    \n",
    "    @property\n",
    "    def behavior_params(self) -> dict[str, Any]:\n",
    "        params = copy.deepcopy(self.stage_params)\n",
    "        params['foraging_id'] = {\n",
    "            'value': self.foraging_id,\n",
    "            'inferrred': False,\n",
    "        }\n",
    "        params['task'] = {\n",
    "            \"id\": self.task_id,\n",
    "            \"sub_id\": \"behavior\",\n",
    "            \"scripts_hash\": self.commit_hash,\n",
    "        }\n",
    "        params[\"mouseID\"] = self.mouse.id\n",
    "        if self.workflow == Workflow.PRETEST:\n",
    "            params[\"max_task_duration_min\"] = 1\n",
    "        return params\n",
    "    \n",
    "    @property\n",
    "    def replay_params(self) -> dict[str, Any]:\n",
    "        \"\"\"`previous_output_path` will be None until the behavior script has run.\"\"\"\n",
    "        params = copy.deepcopy(self.behavior_params)\n",
    "        params[\"mouseID\"] = self.mouse.id\n",
    "        params[\"task\"][\"sub_id\"] = \"replay\"\n",
    "        params[\"previous_output_path\"] = self.get_behavior_output_path()\n",
    "        return params\n",
    "        \n",
    "    @property\n",
    "    def optotagging_params(self) -> dict[str, Any]:\n",
    "        params = copy.deepcopy(self.stage_params[\"opto_params\"])\n",
    "        params.setdefault(\"level_list\", [1.0, 1.2, 1.3])\n",
    "        params[\"mouseID\"] = self.mouse.id\n",
    "        if self.workflow == Workflow.PRETEST:\n",
    "            params[\"operation_mode\"] = \"pretest\"\n",
    "        return params\n",
    "        \n",
    "    @property\n",
    "    def mapping_params(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            'foraging_id': self.behavior_params['foraging_id'],\n",
    "            'gabor_path': self.stage_params['mapping']['gabor_path'],\n",
    "            'flash_path': self.stage_params['mapping']['flash_path'],\n",
    "            # \"output_path\": mapping_output_path,\n",
    "            \"mouseID\": self.mouse.id,\n",
    "            \"task\": {\n",
    "                \"id\": self.task_id,\n",
    "                \"sub_id\": \"mapping\",\n",
    "                \"scripts_hash\": self.commit_hash,\n",
    "            },\n",
    "            \"regimen\": self.mouse.mtrain.regimen['name'],\n",
    "            \"stage\": self.mouse.mtrain.stage['name'],\n",
    "            \"max_mapping_duration_min\": (\n",
    "                self.stage_params['mapping']['max_mapping_duration_min']\n",
    "                if self.workflow != Workflow.PRETEST else 1\n",
    "            ),\n",
    "        }\n",
    "    \n",
    "    def get_behavior_output_path(self) -> str | None:\n",
    "        \"\"\"Return the path to the behavior output file, if one has been created.\"\"\"\n",
    "        \n",
    "        return next(\n",
    "            (\n",
    "                np_config.unc_to_local(p).as_posix() for p in self.stims[0].data_files if self.foraging_id in p.name\n",
    "            ), \n",
    "            None\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def recorders(self) -> tuple[np_services.Service, ...]:\n",
    "        \"\"\"Services to be started before stimuli run, and stopped after. Session-dependent.\"\"\"\n",
    "        match self.workflow:\n",
    "            case Workflow.PRETEST | Workflow.EPHYS:\n",
    "                return (np_services.Sync, np_services.VideoMVR, np_services.OpenEphys)\n",
    "            case Workflow.HAB:\n",
    "                return (np_services.Sync, np_services.VideoMVR)\n",
    "\n",
    "    @property\n",
    "    def stims(self) -> tuple[np_services.Service, ...]:\n",
    "        return (np_services.ScriptCamstim, )\n",
    "    \n",
    "    def initialize_and_test_services(self) -> None:\n",
    "        \"\"\"Configure, initialize (ie. reset), then test all services.\"\"\"\n",
    "        \n",
    "        np_services.MouseDirector.user = self.user.id\n",
    "        np_services.MouseDirector.mouse = self.mouse.id\n",
    "\n",
    "        np_services.OpenEphys.folder = self.session.folder\n",
    "\n",
    "        np_services.NewScaleCoordinateRecorder.log_root = self.session.npexp_path\n",
    "        np_services.NewScaleCoordinateRecorder.log_name = self.platform_json.path.name\n",
    "\n",
    "        for path in (\n",
    "            self.stage_params['stimulus']['params']['image_set'],\n",
    "            self.stage_params['mapping']['flash_path'],\n",
    "            self.stage_params['mapping']['gabor_path'],\n",
    "        ):\n",
    "            if not pathlib.Path(path).exists():\n",
    "                raise FileNotFoundError(f\"{path} doesn't exist or isn't accessible\")\n",
    "        \n",
    "        self.configure_services()\n",
    "\n",
    "        super().initialize_and_test_services()\n",
    "\n",
    "    def update_state(self) -> None:\n",
    "        \"Store useful but non-essential info.\"\n",
    "        self.mouse.state['last_session'] = self.session.id\n",
    "        self.mouse.state['last_vbn_session'] = str(self.workflow)\n",
    "        \n",
    "        if self.mouse == 366122:\n",
    "            return\n",
    "        match self.workflow:\n",
    "            case Workflow.PRETEST:\n",
    "                return\n",
    "            case Workflow.HAB:\n",
    "                self.session.project.state['latest_hab'] = self.session.id\n",
    "            case Workflow.EPHYS:\n",
    "                self.session.project.state['latest_ephys'] = self.session.id\n",
    "                self.session.project.state['sessions'] = self.session.project.state.get('sessions', []) + [self.session.id]\n",
    "    \n",
    "    def log(self, message: str, weblog_name: Optional[str] = None) -> None:\n",
    "        logger.info(message)\n",
    "        if not weblog_name:\n",
    "            weblog_name = self.workflow.name\n",
    "        with contextlib.suppress(AttributeError):\n",
    "            np_logging.web(f'{weblog_name.lower()}_{self.mouse}').info(message)\n",
    "    \n",
    "    def run_script(self, script_name: str | ScriptName) -> None:\n",
    "\n",
    "        if script_name == 'replay' and self.get_behavior_output_path() is None:\n",
    "            raise FileNotFoundError(\"No behavior output file found: cannot run replay script.\")\n",
    "        \n",
    "        params = copy.deepcopy(getattr(self, f'{script_name.replace(\" \", \"_\")}_params'))\n",
    "        \n",
    "        # add mouse and user info for MPE\n",
    "        params['mouse_id'] = str(self.mouse.id)\n",
    "        params['user_id'] = self.user.id if self.user else 'ben.hardcastle'\n",
    "        \n",
    "        np_services.ScriptCamstim.script = self.get_script_content(script_name)\n",
    "        np_services.ScriptCamstim.params = params\n",
    "        \n",
    "        self.update_state()\n",
    "        self.log(f\"{script_name} started\")\n",
    "\n",
    "        np_services.ScriptCamstim.start()\n",
    "        with contextlib.suppress(np_services.resources.zro.ZroError):\n",
    "            while not np_services.ScriptCamstim.is_ready_to_start():\n",
    "                time.sleep(1)\n",
    "            \n",
    "        self.log(f\"{script_name} complete\")\n",
    "\n",
    "        with contextlib.suppress(np_services.resources.zro.ZroError):\n",
    "            np_services.ScriptCamstim.finalize()\n",
    "    \n",
    "    def copy_data_files(self) -> None: \n",
    "        super().copy_data_files()\n",
    "        \n",
    "        # When all processing completes, camstim Agent class passes data and uuid to\n",
    "        # /camstim/lims BehaviorSession class, and write_behavior_data() writes a\n",
    "        # final .pkl with default name YYYYMMDDSSSS_mouseID_foragingID.pkl\n",
    "        # - if we have a foraging ID, we can search for that\n",
    "        if None == (stim_pkl := next(self.session.npexp_path.glob(f'{self.session.date:%y%m%d}*_{self.session.mouse}_*.pkl'), None)):\n",
    "            logger.warning('Did not find stim file on npexp matching the format `YYYYMMDDSSSS_mouseID_foragingID.pkl`')\n",
    "            return\n",
    "        assert stim_pkl\n",
    "        if not self.session.platform_json.foraging_id:\n",
    "            self.session.platform_json.foraging_id = stim_pkl.stem.split('_')[-1]\n",
    "        new_stem = f'{self.session.folder}.stim'\n",
    "        logger.debug(f'Renaming stim file copied to npexp: {stim_pkl} -> {new_stem}')\n",
    "        stim_pkl = stim_pkl.rename(stim_pkl.with_stem(new_stem))\n",
    "        \n",
    "        # remove other stim pkl, which is nearly identical, if it was also copied\n",
    "        for pkl in self.session.npexp_path.glob('*.pkl'):\n",
    "            if (\n",
    "                self.session.folder not in pkl.stem\n",
    "                and \n",
    "                abs(pkl.stat().st_size - stim_pkl.stat().st_size) < 1e6\n",
    "            ):\n",
    "                logger.debug(f'Deleting extra stim pkl copied to npexp: {pkl.stem}')\n",
    "                pkl.unlink()\n",
    "        \n",
    "    def run_stim_desktop_theme_script(self, selection: str) -> None:     \n",
    "        np_services.ScriptCamstim.script = '//allen/programs/mindscope/workgroups/dynamicrouting/ben/change_desktop.py'\n",
    "        np_services.ScriptCamstim.params = {'selection': selection}\n",
    "        np_services.ScriptCamstim.start()\n",
    "        while not np_services.ScriptCamstim.is_ready_to_start():\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    set_grey_desktop_on_stim = functools.partialmethod(run_stim_desktop_theme_script, 'grey')\n",
    "    set_dark_desktop_on_stim = functools.partialmethod(run_stim_desktop_theme_script, 'dark')\n",
    "    reset_desktop_on_stim = functools.partialmethod(run_stim_desktop_theme_script, 'reset')\n",
    "\n",
    "            \n",
    "\n",
    "class Hab(VBNMixin, np_workflows.PipelineHab):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.services = (\n",
    "            np_services.MouseDirector,\n",
    "            np_services.Sync,\n",
    "            np_services.VideoMVR,\n",
    "            np_services.NewScaleCoordinateRecorder,\n",
    "            np_services.SessionCamstim,\n",
    "        )\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "class Ephys(VBNMixin, np_workflows.PipelineEphys):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.services = (\n",
    "            np_services.MouseDirector,\n",
    "            np_services.Sync,\n",
    "            np_services.VideoMVR,\n",
    "            np_services.NewScaleCoordinateRecorder,\n",
    "            np_services.SessionCamstim,\n",
    "            np_services.OpenEphys,\n",
    "        )\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def new_experiment(\n",
    "    mouse: int | str | np_session.Mouse,\n",
    "    user: str | np_session.User,\n",
    "    workflow: Workflow = Workflow.PRETEST,\n",
    ") -> Ephys | Hab:\n",
    "    \"\"\"Create a new experiment for the given mouse and user.\"\"\"\n",
    "    match workflow:\n",
    "        case Workflow.PRETEST | Workflow.EPHYS:\n",
    "            experiment = Ephys(mouse, user)\n",
    "        case Workflow.HAB:\n",
    "            experiment = Hab(mouse, user)\n",
    "        case _:\n",
    "            raise ValueError(f\"Invalid workflow type: {workflow}\")\n",
    "    experiment.workflow = workflow\n",
    "    \n",
    "    with contextlib.suppress(Exception):\n",
    "        np_logging.web(f'barcode_{experiment.workflow.name.lower()}').info(f\"{experiment} created\")\n",
    "            \n",
    "    return experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Select workflow to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_workflow = Workflow.PRETEST\n",
    "# selected_workflow = Workflow.EPHYS\n",
    "# selected_workflow = Workflow.HAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Generate new session\n",
    "Check mouse ID and session are correct: this cell will lock them in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Creating new session for mouse Mouse(366122), operator User('mikayla.carlson')\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"POST /observatory/ecephys_session/create HTTP/1.1\" 200 None\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Set experiment.session to PipelineSession('1371483575_366122_20240607')\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.comp = Mon\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.port = 9000\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.timeout = 10.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.serialization = json\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.rsc_app_id = mouse_director\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.comp = Sync\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.port = 5000\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.data = c$/ProgramData/AIBS_MPE/sync/data\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.gb_per_hr = 2.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.min_rec_hr = 3.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.serialization = pickle\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.rsc_app_id = sync_device\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.comp = Mon\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.port = 50000\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.gb_per_hr = 2.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.min_rec_hr = 3.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.pretest_duration_sec = 5\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.data = c$/ProgramData/AIBS_MPE/mvr/data\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.timeout = 2.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.rsc_app_id = MVR\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.comp = Mon\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_root = c$/MPM_data\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_name = log.csv\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.log_time_fmt = %Y/%m/%d %H:%M:%S.%f\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.max_z_travel = 10000\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_fieldnames = ['last_moved', 'manipulator', 'x', 'y', 'z', 'x_virtual', 'y_virtual', 'z_virtual']\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data = c$/MPM_data\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.rsc_app_id = newscale_motor\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.probe_to_serial_number = {'A': 'SN40911', 'B': 'SN40900', 'C': 'SN40912', 'D': 'SN40913', 'E': 'SN40914', 'F': 'SN40910'}\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.comp = Stim\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.port = 5000\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.data = c$/ProgramData/AIBS_MPE/camstim/data\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.gb_per_hr = 0.2\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.min_rec_hr = 3.0\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.serialization = json\n",
      "18:42 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.rsc_app_id = camstim_agent\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | web | INFO | Ephys(1371483575_366122_20240607) created\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | np_session.components.platform_json | DEBUG | Creating new 1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json with session 1371483575 fields, with write disabled\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json operatorID:  -> mikayla.carlson\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.operatorID = mikayla.carlson\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184205\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184205\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json sessionID:  -> 1371483575\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.sessionID = 1371483575\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184205\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184205\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json mouseID:  -> 366122\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.mouseID = 366122\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.subclasses.pipeline | DEBUG | Could not find experiment start time in //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json: using start of day instead\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.subclasses.pipeline | DEBUG | Could not find experiment end time in //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json: using end of day instead\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /get_behavior_sessions/ HTTP/1.1\" 200 100092\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json project:  -> NeuropixelPlatformDevelopment\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.project = NeuropixelPlatformDevelopment\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371483575\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371483575 HTTP/1.1\" 200 None\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updating 1371483575_366122_20240607_platformD1.json hab: None -> False\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.hab = False\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.workflow_start_time = 20240607184206\n",
      "18:42 | np_session.components.platform_json | DEBUG | Updated 1371483575_366122_20240607_platformD1.json.platform_json_save_time = 20240607184207\n",
      "18:42 | np_session.components.platform_json | DEBUG | PlatformJson wrote to //allen/programs/mindscope/workgroups/np-exp/1371483575_366122_20240607/1371483575_366122_20240607_platformD1.json\n"
     ]
    }
   ],
   "source": [
    "experiment: np_workflows.PipelineExperiment = new_experiment(mouse, user, selected_workflow)\n",
    "session: np_session.PipelineSession = experiment.session\n",
    "platform_json: np_session.PlatformJson = experiment.session.platform_json\n",
    "\n",
    "platform_json.workflow_start_time = npxc.now()\n",
    "hab: bool = isinstance(experiment, Hab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Checks before starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ephys day 2?** \n",
    "Don't forget to adjust probe targeting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f32fbb79cc496dbd3e56e1057d95d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Stage checks:', layout=Layout(min_width='600px')), Checkbox(value=False, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_workflows.check_hardware_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c883062f18114485bcccb9292ce38a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='OpenEphys checks:', layout=Layout(min_width='600px')), Checkbox(value=False, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not hab:\n",
    "    np_workflows.check_openephys_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "## Setup, test, reset all components\n",
    "*This cell must not be skipped!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:33 | np_session.databases.lims2 | DEBUG | Requesting http://lims2/ecephys_sessions.json?id=1371482437\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): lims2:80\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://lims2:80 \"GET /ecephys_sessions.json?id=1371482437 HTTP/1.1\" 200 None\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.platform_json_save_time = 20240607183333\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.workflow_start_time = 20240607183333\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.platform_json_save_time = 20240607183333\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.workflow_start_time = 20240607183333\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.platform_json_save_time = 20240607183333\n",
      "18:33 | np_session.components.platform_json | DEBUG | Updated 1371482437_366122_20240607_platformD1.json.workflow_start_time = 20240607183333\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/regimens/289 HTTP/1.1\" 200 39388\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:33 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.comp = Mon\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.port = 9000\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.timeout = 10.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.serialization = json\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring MouseDirector.rsc_app_id = mouse_director\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.comp = Sync\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.port = 5000\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.data = c$/ProgramData/AIBS_MPE/sync/data\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.gb_per_hr = 2.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.min_rec_hr = 3.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.serialization = pickle\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring Sync.rsc_app_id = sync_device\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.comp = Mon\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.port = 50000\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.gb_per_hr = 2.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.min_rec_hr = 3.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.pretest_duration_sec = 5\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.data = c$/ProgramData/AIBS_MPE/mvr/data\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.timeout = 2.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring VideoMVR.rsc_app_id = MVR\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.comp = Mon\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_root = c$/MPM_data\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_name = log.csv\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.log_time_fmt = %Y/%m/%d %H:%M:%S.%f\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.max_z_travel = 10000\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data_fieldnames = ['last_moved', 'manipulator', 'x', 'y', 'z', 'x_virtual', 'y_virtual', 'z_virtual']\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.data = c$/MPM_data\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.rsc_app_id = newscale_motor\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring NewScaleCoordinateRecorder.probe_to_serial_number = {'A': 'SN40911', 'B': 'SN40900', 'C': 'SN40912', 'D': 'SN40913', 'E': 'SN40914', 'F': 'SN40910'}\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.comp = Stim\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.port = 5000\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.data = c$/ProgramData/AIBS_MPE/camstim/data\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.gb_per_hr = 0.2\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.min_rec_hr = 3.0\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.serialization = json\n",
      "18:33 | np_workflows.shared.base_experiments | DEBUG | Ephys | Configuring SessionCamstim.rsc_app_id = camstim_agent\n",
      "18:33 | np_services.proxies | DEBUG | MouseDirector | Initializing\n",
      "18:33 | np_services.utils | INFO | mouse_director is running on W10DTSM118295\n",
      "18:33 | np_services.proxies | DEBUG | Creating MouseDirector proxy to W10DTSM118295:9000\n",
      "18:33 | np_services.proxies | INFO | Proxy(MouseDirector) initialized: ready for use\n",
      "18:33 | np_services.proxies | DEBUG | MouseDirector | Initialized with mouse 366122, user mikayla.carlson\n",
      "18:33 | np_services.proxies | DEBUG | Testing MouseDirector proxy\n",
      "18:33 | np_services.proxies | DEBUG | MouseDirector proxy connection to W10DTSM118295:9000 confirmed\n",
      "18:33 | np_services.proxies | DEBUG | Proxy(MouseDirector) tested successfully\n",
      "18:33 | np_services.utils | INFO | sync_device is running on W10DT26AD0025\n",
      "18:33 | np_services.proxies | ERROR | Error accessing Sync data path: \\\\W10DT26AD0025\\c$\\ProgramData\\AIBS_MPE\\sync\\data\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py\", line 378, in ensure_config\n",
      "    _ = root.exists()\n",
      "        ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ben.hardcastle\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py\", line 1235, in exists\n",
      "    self.stat()\n",
      "  File \"C:\\Users\\ben.hardcastle\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py\", line 1013, in stat\n",
      "    return os.stat(self, follow_symlinks=follow_symlinks)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [WinError 5] Access is denied: '\\\\\\\\W10DT26AD0025\\\\c$\\\\ProgramData\\\\AIBS_MPE\\\\sync\\\\data'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Sync data path is not accessible: \\\\W10DT26AD0025\\c$\\ProgramData\\AIBS_MPE\\sync\\data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:378\u001b[0m, in \u001b[0;36mSync.ensure_config\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py:1235\u001b[0m, in \u001b[0;36mPath.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self, follow_symlinks)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03mReturn the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03mos.stat() does.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: '\\\\\\\\W10DT26AD0025\\\\c$\\\\ProgramData\\\\AIBS_MPE\\\\sync\\\\data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(ZroError):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_and_test_services\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 162\u001b[0m, in \u001b[0;36mVBNMixin.initialize_and_test_services\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist or isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt accessible\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigure_services()\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_and_test_services\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\github\\np_workflows\\src\\np_workflows\\shared\\base_experiments.py:187\u001b[0m, in \u001b[0;36mWithSession.initialize_and_test_services\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m service \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservices:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(service, Initializable):\n\u001b[1;32m--> 187\u001b[0m         \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(service, Testable):\n\u001b[0;32m    190\u001b[0m         service\u001b[38;5;241m.\u001b[39mtest()\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:132\u001b[0m, in \u001b[0;36mProxy.initialize\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, Startable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mis_ready_to_start():\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, Finalizable):\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:170\u001b[0m, in \u001b[0;36mProxy.get_proxy\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m proxy to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;241m=\u001b[39m zro\u001b[38;5;241m.\u001b[39mDeviceProxy(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mport, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mserialization)\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:384\u001b[0m, in \u001b[0;36mSync.ensure_config\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mexc \u001b[38;5;241m=\u001b[39m exc\n\u001b[0;32m    381\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError accessing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m data path: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, root\n\u001b[0;32m    383\u001b[0m     )\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data path is not accessible: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdata_root \u001b[38;5;241m=\u001b[39m root\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Sync data path is not accessible: \\\\W10DT26AD0025\\c$\\ProgramData\\AIBS_MPE\\sync\\data"
     ]
    }
   ],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.initialize_and_test_services()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MouseDirector: extend lick spout and set position for mouse\n",
    "- so it doesn't fly out to an unknown position when the mouse is on the stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Dip probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    print(np_workflows.dye_info_widget.__doc__)\n",
    "    np_workflows.dye_info_widget(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photodoc of probes in dye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    print(str(session) + '_surface-image1-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe depths in dye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    np_workflows.probe_depth_widget(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# **With mouse on stage**\n",
    "## Before lowering cartridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment.log('Mouse on stage')\n",
    "platform_json.HeadFrameEntryTime = npxc.now()\n",
    "np_workflows.wheel_height_widget(session)\n",
    "np_workflows.check_mouse_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## When cartridge is lowered\n",
    "\n",
    "### Set zoom to 4.0 for photodocs of brain\n",
    "- focus on the brain surface\n",
    "\n",
    "## Photodoc of brain (tap probes if hab Day1 or Day2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "platform_json.CartridgeLowerTime = npxc.now()\n",
    "print(str(session) + '_surface-image2-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ISI map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_workflows.isi_widget(mouse.lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Probe insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    platform_json.ProbeInsertionStartTime = npxc.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extra advance & retract each probe\n",
    "- use NewScale GUI to advance an extra 100 $\\mu m$ at 200 $\\mu m/s$, then reverse 100 $\\mu m$ at the same rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Photodoc before advancing probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    print(str(session) + '_surface-image3-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Settle timer & insertion notes & turn on laser\n",
    "\n",
    "- run both cells now: settle timer will start\n",
    "\n",
    "- fill out probe notes while waiting\n",
    "\n",
    "- press Save once\n",
    "\n",
    "- notes are saved when the timer finishes (button will turn green to confirm)\n",
    "\n",
    "### *also turn on laser while waiting...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    np_workflows.insertion_notes_widget(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    experiment.set_dark_desktop_on_stim()\n",
    "    experiment.log('settle timer started')\n",
    "    np_workflows.print_countdown_timer(minutes=.1 if experiment.workflow.value == 'pretest' else 30)\n",
    "    experiment.log('settle timer finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Photodoc after probes settled, before experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    print(str(session) + '_surface-image4-left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_workflows.pre_stim_check_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### *Before recording: make sure sorting queue is not running!*\n",
    "-  `run_sorting.exe`\n",
    "- window may be minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Start devices recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_exception = Exception()\n",
    "attempts = 3\n",
    "while attempts:\n",
    "    np_logging.getLogger().info('Waiting for recorders to finish processing') \n",
    "    while not all(r.is_ready_to_start() for r in experiment.recorders):\n",
    "        time.sleep(1)\n",
    "    np_logging.getLogger().info('Recorders ready')     \n",
    "    try:\n",
    "        experiment.start_recording()\n",
    "    except AssertionError as exc:\n",
    "        np_logging.getLogger().info('`experiment.start_recording` failed: trying again')\n",
    "        attempts -= 1\n",
    "        last_exception = exc              # exc only exists within the try block\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "else:\n",
    "    np_logging.getLogger().error(f'`experiment.start_recording` failed after multiple attempts', exc_info=last_exception)\n",
    "    raise last_exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## With lickspout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_services.MouseDirector.get_proxy().extend_lick_spout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/regimens/289 HTTP/1.1\" 200 39388\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): mtrain:5000\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://mtrain:5000 \"GET /api/v1/subjects/366122 HTTP/1.1\" 200 110\n",
      "18:42 | urllib3.connectionpool | DEBUG | Starting new HTTP connection (1): stash.corp.alleninstitute.org:80\n",
      "18:42 | urllib3.connectionpool | DEBUG | http://stash.corp.alleninstitute.org:80 \"GET /projects/VB/repos/visual_behavior_scripts/raw/replay_session/behavior_script.py?at=5adfa6e285774719135d0ebcba421f15f6f56168 HTTP/1.1\" 200 None\n",
      "18:42 | root | INFO | behavior started\n",
      "18:42 | web | INFO | behavior started\n",
      "18:42 | np_services.proxies | ERROR | Error accessing ScriptCamstim data path: \\\\W10DT713942\\c$\\ProgramData\\AIBS_MPE\\camstim\\data\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py\", line 530, in ensure_config\n",
      "    _ = root.exists()\n",
      "        ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ben.hardcastle\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py\", line 1235, in exists\n",
      "    self.stat()\n",
      "  File \"C:\\Users\\ben.hardcastle\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py\", line 1013, in stat\n",
      "    return os.stat(self, follow_symlinks=follow_symlinks)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [WinError 5] Access is denied: '\\\\\\\\W10DT713942\\\\c$\\\\ProgramData\\\\AIBS_MPE\\\\camstim\\\\data'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ScriptCamstim data path is not accessible: \\\\W10DT713942\\c$\\ProgramData\\AIBS_MPE\\camstim\\data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:530\u001b[0m, in \u001b[0;36mCamstim.ensure_config\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 530\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py:1235\u001b[0m, in \u001b[0;36mPath.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self, follow_symlinks)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03mReturn the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03mos.stat() does.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;28mself\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: '\\\\\\\\W10DT713942\\\\c$\\\\ProgramData\\\\AIBS_MPE\\\\camstim\\\\data'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(ZroError):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbehavior\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 202\u001b[0m, in \u001b[0;36mVBNMixin.run_script\u001b[1;34m(self, script_name)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_state()\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscript_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 202\u001b[0m \u001b[43mnp_services\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScriptCamstim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(np_services\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mzro\u001b[38;5;241m.\u001b[39mZroError):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np_services\u001b[38;5;241m.\u001b[39mScriptCamstim\u001b[38;5;241m.\u001b[39mis_ready_to_start():\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:603\u001b[0m, in \u001b[0;36mScriptCamstim.start\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstart_script(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mscript, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:170\u001b[0m, in \u001b[0;36mProxy.get_proxy\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39msuppress(\u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m proxy to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;241m=\u001b[39m zro\u001b[38;5;241m.\u001b[39mDeviceProxy(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mport, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mserialization)\n",
      "File \u001b[1;32mc:\\Users\\ben.hardcastle\\github\\np_workflows\\.venv\\Lib\\site-packages\\np_services\\proxies.py:536\u001b[0m, in \u001b[0;36mCamstim.ensure_config\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mexc \u001b[38;5;241m=\u001b[39m exc\n\u001b[0;32m    533\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError accessing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m data path: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, root\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data path is not accessible: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdata_root \u001b[38;5;241m=\u001b[39m root\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: ScriptCamstim data path is not accessible: \\\\W10DT713942\\c$\\ProgramData\\AIBS_MPE\\camstim\\data"
     ]
    }
   ],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.run_script('behavior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Without lickspout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_services.MouseDirector.get_proxy().retract_lick_spout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.run_script('mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.run_script('replay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.run_script('optotagging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Stop recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with contextlib.suppress(ZroError):\n",
    "    experiment.stop_recording_after_stim_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_services.MouseDirector.get_proxy().retract_lick_spout()\n",
    "experiment.reset_desktop_on_stim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Before removing probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:\n",
    "    print(str(session) + '_surface-image5-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## After fully retracting probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not hab:    \n",
    "    print(str(session) + '_surface-image6-left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## After raising cartridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "platform_json.HeadFrameExitTime = npxc.now()\n",
    "\n",
    "np_workflows.finishing_checks_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_json.workflow_complete_time = npxc.now()\n",
    "\n",
    "experiment.finalize_services(*experiment.recorders, *experiment.stims)\n",
    "experiment.validate_services(*experiment.recorders, *experiment.stims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.copy_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add to post-experiment pipeline\n",
    "\n",
    "**hab**\n",
    "- add session to QC queue\n",
    "\n",
    "**ephys**\n",
    "- add session to np-exp upload queue, specifying this rig's Acq as `hostname`\n",
    "    - ensures checksum-validated copy of ephys data on np-exp\n",
    "    - then adds session to spike-sorting queue\n",
    "    - then adds session to QC queue\n",
    "\n",
    "    \n",
    "    #### run *\"process sorting queue .exe\"* on Acq desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hab:\n",
    "    np_jobs.PipelineQCQueue().add_or_update(session, priority=99)\n",
    "else:\n",
    "    np_jobs.PipelineNpexpUploadQueue().add_or_update(session, hostname=np_config.Rig().Acq, priority=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "75a294dbf81199b26941ed5b32867c59e8bcc1170a51aebad9d5a69e8ca694a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
